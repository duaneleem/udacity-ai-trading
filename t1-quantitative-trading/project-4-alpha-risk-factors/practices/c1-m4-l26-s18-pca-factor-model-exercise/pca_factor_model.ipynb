{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA as a Factor Model - Coding Exercises\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "As we learned in the previous lessons, we can use PCA to create a factor model of risk. Our risk factor model represents the return as:\n",
    "\n",
    "$$\n",
    "\\textbf{r} = \\textbf{B}\\textbf{f} + \\textbf{s}\n",
    "$$\n",
    "\n",
    "where $\\textbf{r}$ is a matrix containing the asset returns, $\\textbf{B}$ is a matrix representing the factor exposures, $\\textbf{f}$ is the matrix of factor returns, and $\\textbf{s}$ is the idiosyncratic risk (also known as the company specific risk).\n",
    "\n",
    "In this notebook, we will use real stock data to calculate:\n",
    "\n",
    "* The Factor Exposures (Factor Betas) $\\textbf{B}$\n",
    "* The Factor Returns $\\textbf{f}$\n",
    "* The Idiosyncratic Risk Matrix $\\textbf{S}$\n",
    "* The Factor Covariance Matrix $\\textbf{F}$\n",
    "\n",
    "We will then combine these quantities to create our Risk Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/31/b88ef447d595963c01060998cb329251648acf4a067721b0452c45527eb8/pip-21.2.4-py3-none-any.whl (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 11.9MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 18.1\n",
      "    Uninstalling pip-18.1:\n",
      "      Successfully uninstalled pip-18.1\n",
      "Successfully installed pip-21.2.4\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.6/site-packages (0.30.0)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (38.4.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-57.4.0-py3-none-any.whl (819 kB)\n",
      "Collecting build\n",
      "  Downloading build-0.6.0.post1-py3-none-any.whl (15 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Downloading tomli-1.2.1-py3-none-any.whl (11 kB)\n",
      "Collecting pep517>=0.9.1\n",
      "  Downloading pep517-0.11.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting packaging>=19.0\n",
      "  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 4.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata>=0.22\n",
      "  Downloading importlib_metadata-4.8.1-py3-none-any.whl (17 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=19.0->build) (2.2.0)\n",
      "Installing collected packages: zipp, typing-extensions, tomli, importlib-metadata, pep517, packaging, wheel, setuptools, build\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 16.8\n",
      "    Uninstalling packaging-16.8:\n",
      "      Successfully uninstalled packaging-16.8\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.30.0\n",
      "    Uninstalling wheel-0.30.0:\n",
      "      Successfully uninstalled wheel-0.30.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 38.4.0\n",
      "    Uninstalling setuptools-38.4.0:\n",
      "      Successfully uninstalled setuptools-38.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "Successfully installed build-0.6.0.post1 importlib-metadata-4.8.1 packaging-21.0 pep517-0.11.0 setuptools-57.4.0 tomli-1.2.1 typing-extensions-3.10.0.2 wheel-0.37.0 zipp-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Patch to Help Install Packages.\n",
    "!{sys.executable} -m pip install --upgrade pip  \n",
    "!{sys.executable} -m pip install --upgrade wheel setuptools build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zipline===1.3.0\n",
      "  Using cached zipline-1.3.0.tar.gz (2.5 MB)\n",
      "Collecting sqlalchemy===1.3.22\n",
      "  Downloading SQLAlchemy-1.3.22-cp36-cp36m-manylinux2010_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 5.4 MB/s eta 0:00:01     |████████████                    | 471 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.13.3\n",
      "  Using cached numpy-1.13.3-cp36-cp36m-manylinux1_x86_64.whl (17.0 MB)\n",
      "Requirement already satisfied: pip>=7.1.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (21.2.4)\n",
      "Requirement already satisfied: setuptools>18.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (57.4.0)\n",
      "Collecting Logbook>=0.12.5\n",
      "  Using cached Logbook-1.5.3.tar.gz (85 kB)\n",
      "Requirement already satisfied: pytz>=2016.4 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (2017.3)\n",
      "Collecting requests-file>=1.4.1\n",
      "  Using cached requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: scipy>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (1.2.1)\n",
      "Collecting pandas<=0.22,>=0.18.1\n",
      "  Using cached pandas-0.22.0-cp36-cp36m-manylinux1_x86_64.whl (26.2 MB)\n",
      "Collecting pandas-datareader>=0.2.1\n",
      "  Using cached pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: patsy>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (1.11.0)\n",
      "Requirement already satisfied: requests>=2.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (2.18.4)\n",
      "Requirement already satisfied: Cython>=0.25.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (0.29.7)\n",
      "Collecting cyordereddict>=0.2.2\n",
      "  Using cached cyordereddict-1.0.0.tar.gz (138 kB)\n",
      "Collecting bottleneck>=1.0.0\n",
      "  Using cached Bottleneck-1.3.2.tar.gz (88 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting contextlib2>=0.4.0\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: decorator>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (4.0.11)\n",
      "Requirement already satisfied: networkx<2.0,>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (1.11)\n",
      "Requirement already satisfied: numexpr>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (2.6.4)\n",
      "Collecting bcolz<1,>=0.12.1\n",
      "  Using cached bcolz-0.12.1.tar.gz (622 kB)\n",
      "Requirement already satisfied: click>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (6.7)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (0.8.2)\n",
      "Collecting multipledispatch>=0.4.8\n",
      "  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (1.0)\n",
      "Requirement already satisfied: Mako>=1.0.1 in /opt/conda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg (from zipline===1.3.0->-r requirements.txt (line 1)) (1.0.7)\n",
      "Collecting alembic>=0.7.7\n",
      "  Downloading alembic-1.7.1-py3-none-any.whl (208 kB)\n",
      "\u001b[K     |████████████████████████████████| 208 kB 25.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers>=1.4.4\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting intervaltree>=2.1.0\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "Collecting lru-dict>=1.1.4\n",
      "  Downloading lru-dict-1.1.7.tar.gz (10 kB)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tables>=3.3.0\n",
      "  Downloading tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 20.6 MB/s eta 0:00:01     |██▍                             | 317 kB 20.6 MB/s eta 0:00:01     |███████████▋                    | 1.6 MB 20.6 MB/s eta 0:00:01     |█████████████████████           | 2.8 MB 20.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting trading-calendars>=1.0.1\n",
      "  Downloading trading_calendars-2.1.1.tar.gz (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 25.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from alembic>=0.7.7->zipline===1.3.0->-r requirements.txt (line 1)) (4.8.1)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.2.2-py3-none-any.whl (27 kB)\n",
      "Collecting pandas-datareader>=0.2.1\n",
      "  Downloading pandas_datareader-0.9.0-py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 13.0 MB/s eta 0:00:01    |████████████████████████▍       | 81 kB 24.0 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading pandas_datareader-0.8.1-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 26.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: lxml in /opt/conda/lib/python3.6/site-packages (from pandas-datareader>=0.2.1->zipline===1.3.0->-r requirements.txt (line 1)) (4.1.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1)) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1)) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1)) (2019.11.28)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->alembic>=0.7.7->zipline===1.3.0->-r requirements.txt (line 1)) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->alembic>=0.7.7->zipline===1.3.0->-r requirements.txt (line 1)) (3.5.0)\n",
      "Building wheels for collected packages: zipline, bcolz, bottleneck, cyordereddict, empyrical, intervaltree, Logbook, lru-dict, trading-calendars\n",
      "  Building wheel for zipline (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for zipline: filename=zipline-1.3.0-cp36-cp36m-linux_x86_64.whl size=5212146 sha256=72c5513af4ec9e93b869c59f493f0b13b2b7e2a984296ffe58e7e4540c7861d1\n",
      "  Stored in directory: /root/.cache/pip/wheels/47/3e/96/5819c9453bd1cbe7cd0a9356df16744b1e2366e9b25071a9bb\n",
      "  Building wheel for bcolz (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bcolz: filename=bcolz-0.12.1-cp36-cp36m-linux_x86_64.whl size=1112261 sha256=59b43e3c17ca3d4727bd614566bf278bf35eebae23e58f7c0b7288070606227b\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/51/d6/173c1dabc3904530cd9527026946789e2a065b004916e5c5bb\n",
      "  Building wheel for bottleneck (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bottleneck: filename=Bottleneck-1.3.2-cp36-cp36m-linux_x86_64.whl size=331700 sha256=4c616801314b63318f272f82956381ec219637d66461a9b30a934b44aef55de9\n",
      "  Stored in directory: /root/.cache/pip/wheels/f7/a7/14/9be836efed01ac0eb3c125ac006c143b55ebf689269877d0e8\n",
      "  Building wheel for cyordereddict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cyordereddict: filename=cyordereddict-1.0.0-cp36-cp36m-linux_x86_64.whl size=169592 sha256=e786e809ec33d306ebea1808673d9f9dea9799ef425f1947ea05cdda7cc7c8e1\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/ff/1a/5f19b34a20e254f738ef53a8469e9e92ee13e66d54de3ea89c\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39777 sha256=ffadc10774ca35414405a54984847850238c535b653f1f4b7a8453d022c245f0\n",
      "  Stored in directory: /root/.cache/pip/wheels/82/0b/5a/ca1ca63ffb9d995bd8f0d3a75f14e89d54e1b0caee61b68c02\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=a09a69c6705869b34318f5a07b1b6c3383eb214aa14be3592eb7e65808264c50\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/e6/3f/1616b381f981006664dd5123f06b231bbbb2e7d604a417e2fd\n",
      "  Building wheel for Logbook (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Logbook: filename=Logbook-1.5.3-cp36-cp36m-linux_x86_64.whl size=66394 sha256=1ebb89a11dd1413e7e7882639e82256c2ffb04c40fa6e43b1f32d6351fbe9778\n",
      "  Stored in directory: /root/.cache/pip/wheels/27/4c/d7/c08e0670a3318441d3bd095149eb6e86e21656f102530ac8b6\n",
      "  Building wheel for lru-dict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lru-dict: filename=lru_dict-1.1.7-cp36-cp36m-linux_x86_64.whl size=30522 sha256=1b9fdc2ed374b18b4064c7ded52c718ab118d46660728973556be8e2277562bd\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/61/6d/2c1544021f8e787b602ed799d88e0d1ab4437ffb09a04102a0\n",
      "  Building wheel for trading-calendars (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for trading-calendars: filename=trading_calendars-2.1.1-py3-none-any.whl size=140937 sha256=30638419ba2bc59c0f3148feb8ed2a6f6403601fe06102777af0bbb13ef52f49\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/3d/ae/394cfeb7b26c44a6c0bfdd42ab2f8ab899cefc00c4baa820f3\n",
      "Successfully built zipline bcolz bottleneck cyordereddict empyrical intervaltree Logbook lru-dict trading-calendars\n",
      "Installing collected packages: numpy, pandas, sqlalchemy, sortedcontainers, pandas-datareader, importlib-resources, trading-calendars, tables, requests-file, multipledispatch, lru-dict, Logbook, intervaltree, empyrical, cyordereddict, contextlib2, bottleneck, bcolz, alembic, zipline\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 0.23.3\n",
      "    Uninstalling pandas-0.23.3:\n",
      "      Successfully uninstalled pandas-0.23.3\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.1.13\n",
      "    Uninstalling SQLAlchemy-1.1.13:\n",
      "      Successfully uninstalled SQLAlchemy-1.1.13\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "Successfully installed Logbook-1.5.3 alembic-1.7.1 bcolz-0.12.1 bottleneck-1.3.2 contextlib2-21.6.0 cyordereddict-1.0.0 empyrical-0.5.5 importlib-resources-5.2.2 intervaltree-3.1.0 lru-dict-1.1.7 multipledispatch-0.6.0 numpy-1.13.3 pandas-0.22.0 pandas-datareader-0.8.1 requests-file-1.5.1 sortedcontainers-2.4.0 sqlalchemy-1.3.22 tables-3.6.1 trading-calendars-2.1.1 zipline-1.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Returns\n",
    "\n",
    "In this notebook, we will get the stock returns using Zipline and data from Quotemedia, just as we learned in previous lessons. The function `get_returns(start_date, end_date)` in the `utils` module, gets the data from the Quotemedia data bundle and produces the stock returns for the given `start_date` and `end_date`. You are welcome to take a look at the `utils` module to see how this is done.\n",
    "\n",
    "In the code below, we use `utils.get_returns` funtion to get the returns for stock data between `2011-01-05` and `2016-01-05`. You can change the start and end dates, but if you do, you have to make sure the dates are valid trading dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Equity(0 [A])</th>\n",
       "      <th>Equity(1 [AAL])</th>\n",
       "      <th>Equity(2 [AAP])</th>\n",
       "      <th>Equity(3 [AAPL])</th>\n",
       "      <th>Equity(4 [ABBV])</th>\n",
       "      <th>Equity(5 [ABC])</th>\n",
       "      <th>Equity(6 [ABT])</th>\n",
       "      <th>Equity(7 [ACN])</th>\n",
       "      <th>Equity(8 [ADBE])</th>\n",
       "      <th>Equity(9 [ADI])</th>\n",
       "      <th>...</th>\n",
       "      <th>Equity(481 [XL])</th>\n",
       "      <th>Equity(482 [XLNX])</th>\n",
       "      <th>Equity(483 [XOM])</th>\n",
       "      <th>Equity(484 [XRAY])</th>\n",
       "      <th>Equity(485 [XRX])</th>\n",
       "      <th>Equity(486 [XYL])</th>\n",
       "      <th>Equity(487 [YUM])</th>\n",
       "      <th>Equity(488 [ZBH])</th>\n",
       "      <th>Equity(489 [ZION])</th>\n",
       "      <th>Equity(490 [ZTS])</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-07 00:00:00+00:00</th>\n",
       "      <td>0.008437</td>\n",
       "      <td>0.014230</td>\n",
       "      <td>0.026702</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>-0.007127</td>\n",
       "      <td>-0.005818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001838</td>\n",
       "      <td>-0.005619</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>-0.004044</td>\n",
       "      <td>-0.013953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>-0.010458</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-10 00:00:00+00:00</th>\n",
       "      <td>-0.004174</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.018852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005714</td>\n",
       "      <td>-0.008896</td>\n",
       "      <td>-0.008854</td>\n",
       "      <td>0.028714</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>-0.006081</td>\n",
       "      <td>0.010466</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>-0.017945</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11 00:00:00+00:00</th>\n",
       "      <td>-0.001886</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>-0.005927</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>0.013717</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006470</td>\n",
       "      <td>0.035676</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-12 00:00:00+00:00</th>\n",
       "      <td>0.017254</td>\n",
       "      <td>-0.008237</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005979</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>0.022969</td>\n",
       "      <td>0.017950</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.027182</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>-0.011903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-13 00:00:00+00:00</th>\n",
       "      <td>-0.004559</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>-0.004451</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>-0.005719</td>\n",
       "      <td>-0.005012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030499</td>\n",
       "      <td>-0.003217</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>-0.018235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005084</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>-0.009178</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Equity(0 [A])  Equity(1 [AAL])  Equity(2 [AAP])  \\\n",
       "2011-01-07 00:00:00+00:00       0.008437         0.014230         0.026702   \n",
       "2011-01-10 00:00:00+00:00      -0.004174         0.006195         0.007435   \n",
       "2011-01-11 00:00:00+00:00      -0.001886        -0.043644        -0.005927   \n",
       "2011-01-12 00:00:00+00:00       0.017254        -0.008237         0.013387   \n",
       "2011-01-13 00:00:00+00:00      -0.004559         0.000955         0.003031   \n",
       "\n",
       "                           Equity(3 [AAPL])  Equity(4 [ABBV])  \\\n",
       "2011-01-07 00:00:00+00:00          0.007146               0.0   \n",
       "2011-01-10 00:00:00+00:00          0.018852               0.0   \n",
       "2011-01-11 00:00:00+00:00         -0.002367               0.0   \n",
       "2011-01-12 00:00:00+00:00          0.008133               0.0   \n",
       "2011-01-13 00:00:00+00:00          0.003657               0.0   \n",
       "\n",
       "                           Equity(5 [ABC])  Equity(6 [ABT])  Equity(7 [ACN])  \\\n",
       "2011-01-07 00:00:00+00:00         0.001994         0.004165         0.001648   \n",
       "2011-01-10 00:00:00+00:00        -0.005714        -0.008896        -0.008854   \n",
       "2011-01-11 00:00:00+00:00         0.009783        -0.002067         0.013717   \n",
       "2011-01-12 00:00:00+00:00        -0.005979        -0.001011         0.022969   \n",
       "2011-01-13 00:00:00+00:00         0.014925        -0.004451        -0.000400   \n",
       "\n",
       "                           Equity(8 [ADBE])  Equity(9 [ADI])  \\\n",
       "2011-01-07 00:00:00+00:00         -0.007127        -0.005818   \n",
       "2011-01-10 00:00:00+00:00          0.028714         0.002926   \n",
       "2011-01-11 00:00:00+00:00          0.000607         0.008753   \n",
       "2011-01-12 00:00:00+00:00          0.017950         0.000257   \n",
       "2011-01-13 00:00:00+00:00         -0.005719        -0.005012   \n",
       "\n",
       "                                 ...          Equity(481 [XL])  \\\n",
       "2011-01-07 00:00:00+00:00        ...                 -0.001838   \n",
       "2011-01-10 00:00:00+00:00        ...                  0.000947   \n",
       "2011-01-11 00:00:00+00:00        ...                  0.001314   \n",
       "2011-01-12 00:00:00+00:00        ...                  0.004986   \n",
       "2011-01-13 00:00:00+00:00        ...                  0.030499   \n",
       "\n",
       "                           Equity(482 [XLNX])  Equity(483 [XOM])  \\\n",
       "2011-01-07 00:00:00+00:00           -0.005619           0.005461   \n",
       "2011-01-10 00:00:00+00:00            0.007814          -0.006081   \n",
       "2011-01-11 00:00:00+00:00            0.010179           0.007442   \n",
       "2011-01-12 00:00:00+00:00            0.015666           0.011763   \n",
       "2011-01-13 00:00:00+00:00           -0.003217           0.001694   \n",
       "\n",
       "                           Equity(484 [XRAY])  Equity(485 [XRX])  \\\n",
       "2011-01-07 00:00:00+00:00           -0.004044          -0.013953   \n",
       "2011-01-10 00:00:00+00:00            0.010466           0.009733   \n",
       "2011-01-11 00:00:00+00:00            0.007351           0.006116   \n",
       "2011-01-12 00:00:00+00:00            0.027182           0.004386   \n",
       "2011-01-13 00:00:00+00:00            0.000547          -0.018235   \n",
       "\n",
       "                           Equity(486 [XYL])  Equity(487 [YUM])  \\\n",
       "2011-01-07 00:00:00+00:00                0.0           0.012457   \n",
       "2011-01-10 00:00:00+00:00                0.0           0.001440   \n",
       "2011-01-11 00:00:00+00:00                0.0          -0.006470   \n",
       "2011-01-12 00:00:00+00:00                0.0           0.002631   \n",
       "2011-01-13 00:00:00+00:00                0.0          -0.005084   \n",
       "\n",
       "                           Equity(488 [ZBH])  Equity(489 [ZION])  \\\n",
       "2011-01-07 00:00:00+00:00          -0.000181           -0.010458   \n",
       "2011-01-10 00:00:00+00:00           0.007784           -0.017945   \n",
       "2011-01-11 00:00:00+00:00           0.035676            0.007467   \n",
       "2011-01-12 00:00:00+00:00           0.014741           -0.011903   \n",
       "2011-01-13 00:00:00+00:00          -0.004665           -0.009178   \n",
       "\n",
       "                           Equity(490 [ZTS])  \n",
       "2011-01-07 00:00:00+00:00                0.0  \n",
       "2011-01-10 00:00:00+00:00                0.0  \n",
       "2011-01-11 00:00:00+00:00                0.0  \n",
       "2011-01-12 00:00:00+00:00                0.0  \n",
       "2011-01-13 00:00:00+00:00                0.0  \n",
       "\n",
       "[5 rows x 490 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "# Get the returns for the fiven start and end date. Both dates must be valid trading dates\n",
    "returns = utils.get_returns(start_date='2011-01-05', end_date='2016-01-05')\n",
    "\n",
    "# Display the first rows of the returns\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Factor Exposures\n",
    "\n",
    "In the code below, write a function, `factor_betas(pca, factor_beta_indices, factor_beta_columns)` that calculates the factor exposures from Scikit-Learn's `PCA()` class. Remember the matrix of factor exposures, $\\textbf{B}$, describes the coordintates of the Principal Components in the original basis. The `pca` parameter must be a Scikit-Learn's pca object, that has fit the model with the returns. In other words, you must first run `pca.fit(returns)` before passing this parameter into the function. Later in this notebook we will create a function, `fit_pca()`, that will fit the pca model and return the `pca`object. The `factor_beta_indices` parameter must be a 1 dimensional ndarray containg the column names of the `returns` dataframe. The `factor_beta_columns` parameter must be a 1 dimensional ndarray containing evenly spaced integers from 0 up to the number of principal components you used in your `pca` model minus one. For example, if you used 5 principal compoenents in your `pca` model, `pca = PCA(n_components = 5)`, then `factor_beta_columns = [0, 1, 2, 3, 4]`. This function has to return a Pandas dataframe with the factor exposures, where the `factor_beta_indices` correspond to the indices of the dataframe and the `factor_beta_columns` correspond to the column names of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def factor_betas(pca, factor_beta_indices, factor_beta_columns):\n",
    "    \n",
    "    #Implement Function\n",
    "    \n",
    "    #assert len(factor_return_indices.shape) == 1\n",
    "    #assert len(factor_return_columns.shape) == 1\n",
    "    \n",
    "    return pd.DataFrame(pca.components_.T, factor_beta_indices, factor_beta_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Factor Retuns\n",
    "\n",
    "In the code below, write a function, `factor_returns(pca, returns, factor_return_indices, factor_return_columns)` that calculates the factor returns from Scikit-Learn's `PCA()` class. Remember the matrix of factor returns, $\\textbf{f}$, represents the `returns` written in the **new** basis. The `pca` parameter must be a Scikit-Learn's pca object, that has fit the model with the returns. In other words, you must first run `pca.fit(returns)` before passing this parameter into the function. Later in this notebook we will create a function, `fit_pca()`, that will fit the pca model and return the `pca`object. The `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `factor_return_indices` parameter must be a 1 dimensional ndarray containing the trading dates (Pandas `DatetimeIndex`) in the `returns` dataframe. The `factor_return_columns` parameter must be a 1 dimensional ndarray containing evenly spaced integers from 0 up to the number of principal components you used in your `pca` model minus one. For example, if you used 5 principal compoenents in your `pca` model, `pca = PCA(n_components = 5)`, then `factor_beta_columns = [0, 1, 2, 3, 4]`. This function has to return a Pandas dataframe with the factor returns, where the `factor_return_indices` correspond to the indices of the dataframe and the `factor_return_columns` correspond to the column names of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def factor_returns(pca, returns, factor_return_indices, factor_return_columns):\n",
    "    \n",
    "    #Implement Function\n",
    "    \n",
    "    assert len(factor_return_indices.shape) == 1\n",
    "    assert len(factor_return_columns.shape) == 1\n",
    "    \n",
    "    return pd.DataFrame(pca.transform(returns), factor_return_indices, factor_return_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Idiosyncratic Risk Matrix\n",
    "\n",
    "Let's review how we can calculate the Idiosyncratic Risk Matrix $\\textbf{S}$. We know that: \n",
    "\n",
    "$$\n",
    "\\textbf{s} = \\textbf{r} - \\textbf{B}\\textbf{f}\n",
    "$$\n",
    "\n",
    "We refer to $\\textbf{s}$ as the residuals. To calculate the idiosyncratic or specific risk matrix $\\textbf{S}$, we have to calculate the covariance matrix of the residuals, $\\textbf{s}$, and set the off-diagonal elements to zero. \n",
    "\n",
    "With this in mind, in the code below cerate a function, `idiosyncratic_var_matrix(returns, factor_returns, factor_betas, ann_factor)` that calclates the **annualized** Idiosyncratic Risk Matrix. The `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `factor_returns` parameter is the output of the `factor_returns()` function created above. Similarly, the `factor_betas` parameter is the output of the `factor_betas()` function created above. The `ann_factor` parameter is an integer representing the annualization factor. \n",
    "\n",
    "Remember that if the `returns` time series are daily returns, then when we calculate the Idiosyncratic Risk Matrix we will get values on a daily basis. We can annualize these values simply by multiplying the whole Idiosyncratic Risk Matrix by an annualization factor of 252. Remember we don't need the square root of the factor because our numbers here are variances not standard deviations.\n",
    "\n",
    "The function must return a pandas dataframe with the annualized Idiosyncratic Risk Matrix containing the covariance of the residuals in its main diagonal and with all the off-diagonal elements set to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def idiosyncratic_var_matrix(returns, factor_returns, factor_betas, ann_factor):\n",
    "    \n",
    "    #Implement Function\n",
    "    common_returns_ = pd.DataFrame(np.dot(factor_returns, factor_betas.T), returns.index, returns.columns)\n",
    "    \n",
    "    residuals_ = (returns - common_returns_)\n",
    "    \n",
    "    return pd.DataFrame(np.diag(np.var(residuals_))*ann_factor, returns.columns, returns.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Factor Covariance Matrix\n",
    "\n",
    "To calculate the annualized factor covariance matrix, $\\textbf{F}$, we use the following equation:\n",
    "\n",
    "$$\n",
    "\\textbf{F} = \\frac{1}{N -1}\\textbf{f}\\textbf{f}^T\n",
    "$$\n",
    "\n",
    "where, $N$ is the number of elements in $\\textbf{f}$. Recall that the factor covariance matrix, $\\textbf{F}$, is a diagonal matrix.\n",
    "\n",
    "With this in mind, create a function, `factor_cov_matrix(factor_returns, ann_factor)` that calculates the annualized factor covariance matrix from the factor returns $\\textbf{f}$. The `factor_returns` parameter is the output of the `factor_returns()` function created above and the `ann_factor` parameter is an integer representing the annualization factor. The function must return a diagonal numpy ndarray \n",
    "\n",
    "**HINT :** You can calculate the factor covariance matrix $\\textbf{F}$ very easily using Numpy's `.var` method. The $\\frac{1}{N -1}$ factor can be taken into account using the `ddof` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def factor_cov_matrix(factor_returns, ann_factor):\n",
    " \n",
    "    #Implement Function\n",
    "    return np.diag(factor_returns.var(axis=0, ddof=1) * ann_factor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Perfom PCA\n",
    "\n",
    "In the code below, create a function, `fit_pca(returns, num_factor_exposures, svd_solver)` that uses Scikit-Learn's `PCA()` class to fit the `returns` dataframe with the given number of `num_factor_exposures` (Principal Components) and with the given `svd_solver`. The `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `num_factor_exposures` parameter is an integer representing the number of Principal Components you want to use in your PCA algorithm. The `svd_solver` parameter is a string that determines the type of solver you want to use in your PCA algorithm. To see the type of solvers that you can use, see the [Scikit-Learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). The function must fit the `returns` and return the `pca` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def fit_pca(returns, num_factor_exposures, svd_solver):\n",
    "\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    # Docs: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "    pca = PCA(n_components=num_factor_exposures, svd_solver=svd_solver)\n",
    "    pca.fit(returns)\n",
    "    \n",
    "    return pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Create The Risk Model\n",
    "\n",
    "\n",
    "In the code below, create a class:\n",
    "\n",
    "```python\n",
    "class RiskModel(object):\n",
    "    def __init__(self, returns, ann_factor, num_factor_exposures, pca):\n",
    "```\n",
    "\n",
    "where the `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `ann_factor` parameter is an integer representing the annualization factor. The `num_factor_exposures` parameter is an integer representing the number of Principal Components you want to use in your PCA algorithm. The `pca` parameter is the output of the `fit_pca()` function created above. The class must contain all the fucntions created above. For example, to include the Factor covariance matrix we will use:\n",
    "\n",
    "```python\n",
    "self.factor_cov_matrix_ = factor_cov_matrix(self.factor_returns_, ann_factor)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RiskModel(object):\n",
    "    def __init__(self, returns, ann_factor, num_factor_exposures, pca):\n",
    "\n",
    "        self.factor_betas_ = factor_betas(pca, returns.columns.values, np.arange(num_factor_exposures))\n",
    "        self.factor_returns_ = factor_returns(pca, returns, returns.index, np.arange(num_factor_exposures))\n",
    "        self.factor_cov_matrix_ = factor_cov_matrix(self.factor_returns_, ann_factor)\n",
    "        self.idiosyncratic_var_matrix_ = idiosyncratic_var_matrix(returns, self.factor_returns_, self.factor_betas_, ann_factor)\n",
    "\n",
    "# Set the annualized factor\n",
    "ann_factor = 252\n",
    "\n",
    "# Set the number of factor exposures (principal components) for the PCA algorithm\n",
    "num_factor_exposures = 20\n",
    "\n",
    "# Set the svd solver for the PCA algorithm\n",
    "svd_solver = 'full'\n",
    "\n",
    "# Fit the PCA Model using the fit_pca() fucntion \n",
    "pca = fit_pca(returns, num_factor_exposures, svd_solver)\n",
    "\n",
    "# Create a RiskModel object\n",
    "rm = RiskModel(returns, ann_factor, num_factor_exposures, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Factor Exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the Factor Exposures\n",
    "rm.factor_betas_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Factor Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the Factor Returns\n",
    "rm.factor_returns_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Idiosyncratic Risk Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the Idiosyncratic Risk Matrix\n",
    "rm.idiosyncratic_var_matrix_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Factor Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the Factor Covariance Matrix\n",
    "rm.factor_cov_matrix_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View The Percent of Variance Explained by Each Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [10.0, 6.0]\n",
    "\n",
    "# Make the bar plot\n",
    "plt.bar(np.arange(num_factor_exposures), pca.explained_variance_ratio_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the first factor dominates. The precise defintion of each factor in a latent model is unknown, however we can guess at the likely intepretation.\n",
    "\n",
    "# View The Factor Returns\n",
    "\n",
    "Remember that the factors returns don't necessarily have direct interpretations in the real world but you can thinik of them as returns time series for some kind of latent or unknown driver of return variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [10.0, 6.0]\n",
    "\n",
    "rm.factor_returns_.loc[:,0:5].cumsum().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "[Solution notebook](pca_factor_model_solution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
