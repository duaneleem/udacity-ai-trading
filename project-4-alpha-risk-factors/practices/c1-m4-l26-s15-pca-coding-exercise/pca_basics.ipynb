{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Basics - Coding Exercises\n",
    "\n",
    "In this notebook you will apply what you learned about PCA in the previous lesson to real stock data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zipline>==1.3.0\n",
      "  Using cached zipline-1.4.1-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: bottleneck>=1.0.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: setuptools>18.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (57.4.0)\n",
      "Requirement already satisfied: patsy>=0.4.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: h5py>=2.7.1 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: tables>=3.4.3 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (3.6.1)\n",
      "Requirement already satisfied: numexpr>=2.6.1 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (2.7.3)\n",
      "Collecting alembic>=0.7.7\n",
      "  Using cached alembic-1.7.1-py3-none-any.whl (208 kB)\n",
      "Requirement already satisfied: bcolz>=0.12.1 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: pandas-datareader<0.9.0,>=0.2.1 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (0.8.1)\n",
      "Requirement already satisfied: Logbook>=0.12.5 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.5.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.11.0)\n",
      "Collecting pandas<=0.22,>=0.18.1\n",
      "  Using cached pandas-0.22.0-cp36-cp36m-manylinux1_x86_64.whl (26.2 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: requests>=2.9.1 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (2.26.0)\n",
      "Requirement already satisfied: iso4217>=1.6.20180829 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.6.20180829)\n",
      "Requirement already satisfied: lru-dict>=1.1.4 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.1.7)\n",
      "Requirement already satisfied: empyrical>=0.5.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (0.5.5)\n",
      "Requirement already satisfied: multipledispatch>=0.6.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (0.11.1)\n",
      "Requirement already satisfied: pip>=7.1.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (21.2.3)\n",
      "Requirement already satisfied: iso3166>=0.9 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.17.1 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: pytz>=2018.5 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (2021.1)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (0.12.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.0.8 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.3.5)\n",
      "Requirement already satisfied: click>=4.0.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (8.0.1)\n",
      "Requirement already satisfied: python-interface>=1.5.3 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.6.1)\n",
      "Requirement already satisfied: trading-calendars>=1.6.1 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: intervaltree>=2.1.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: networkx<2.0,>=1.9.1 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from zipline>==1.3.0->-r requirements.txt (line 1)) (1.11)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from alembic>=0.7.7->zipline>==1.3.0->-r requirements.txt (line 1)) (4.6.3)\n",
      "Requirement already satisfied: Mako in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from alembic>=0.7.7->zipline>==1.3.0->-r requirements.txt (line 1)) (1.1.4)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from alembic>=0.7.7->zipline>==1.3.0->-r requirements.txt (line 1)) (5.2.2)\n",
      "Requirement already satisfied: cached-property in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from h5py>=2.7.1->zipline>==1.3.0->-r requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from intervaltree>=2.1.0->zipline>==1.3.0->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from networkx<2.0,>=1.9.1->zipline>==1.3.0->-r requirements.txt (line 1)) (5.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from pandas<=0.22,>=0.18.1->zipline>==1.3.0->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: lxml in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from pandas-datareader<0.9.0,>=0.2.1->zipline>==1.3.0->-r requirements.txt (line 1)) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from requests>=2.9.1->zipline>==1.3.0->-r requirements.txt (line 1)) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from requests>=2.9.1->zipline>==1.3.0->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from requests>=2.9.1->zipline>==1.3.0->-r requirements.txt (line 1)) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from requests>=2.9.1->zipline>==1.3.0->-r requirements.txt (line 1)) (2021.5.30)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from importlib-metadata->alembic>=0.7.7->zipline>==1.3.0->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from importlib-metadata->alembic>=0.7.7->zipline>==1.3.0->-r requirements.txt (line 1)) (3.10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/envs/UdacityAI/lib/python3.6/site-packages (from Mako->alembic>=0.7.7->zipline>==1.3.0->-r requirements.txt (line 1)) (2.0.1)\n",
      "Installing collected packages: pandas, alembic, zipline\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "Successfully installed alembic-1.7.1 pandas-0.22.0 zipline-1.4.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Returns\n",
    "\n",
    "In the previous lesson we used 2-dimensional randomly correlated data to see how we can use PCA to for dimensionality reduction. In this notebook, we will do the same but for 490-dimensional data of stock returns. We will get the stock returns using Zipline and data from Quotemedia, just as we learned in previous lessons. The function `get_returns(start_date, end_date)` in the `utils` module, gets the data from the Quotemedia data bundle and produces the stock returns for the given `start_date` and `end_date`. You are welcome to take a look at the `utils` module to see how this is done.\n",
    "\n",
    "In the code below, we use `utils.get_returns` funtion to get the returns for stock data between `2011-01-05` and `2016-01-05`. You can change the start and end dates, but if you do, you have to make sure the dates are valid trading dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no data for bundle 'm4-quiz-eod-quotemedia' on or before 2021-09-01 06:20:56.420142+00:00\nmaybe you need to run: $ zipline ingest -b m4-quiz-eod-quotemedia",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/UdacityAI/lib/python3.6/site-packages/zipline/data/bundles/core.py\u001b[0m in \u001b[0;36mmost_recent_data\u001b[0;34m(bundle_name, timestamp, environ)\u001b[0m\n\u001b[1;32m    471\u001b[0m             candidates = os.listdir(\n\u001b[0;32m--> 472\u001b[0;31m                 \u001b[0mpth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbundle_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m             )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyan/work/project-4-alpha-risk-factors/practices/c1-m4-l26-s15-pca-coding-exercise/../../data/module_4_quizzes_eod/data/m4-quiz-eod-quotemedia'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e91f670db46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the returns for the fiven start and end date. Both dates must be valid trading dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2011-01-05'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2016-01-05'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/work/project-4-alpha-risk-factors/practices/c1-m4-l26-s15-pca-coding-exercise/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Load the data bundle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mbundle_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbundles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbundle_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Create a screen for our Pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/UdacityAI/lib/python3.6/site-packages/zipline/data/bundles/core.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, environ, timestamp)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mtimestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmost_recent_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         return BundleData(\n\u001b[1;32m    515\u001b[0m             asset_finder=AssetFinder(\n",
      "\u001b[0;32m/opt/conda/envs/UdacityAI/lib/python3.6/site-packages/zipline/data/bundles/core.py\u001b[0m in \u001b[0;36mmost_recent_data\u001b[0;34m(bundle_name, timestamp, environ)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 'maybe you need to run: $ zipline ingest -b {bundle}'.format(\n\u001b[1;32m    488\u001b[0m                     \u001b[0mbundle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbundle_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                     \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m                 ),\n\u001b[1;32m    491\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: no data for bundle 'm4-quiz-eod-quotemedia' on or before 2021-09-01 06:20:56.420142+00:00\nmaybe you need to run: $ zipline ingest -b m4-quiz-eod-quotemedia"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "# Get the returns for the fiven start and end date. Both dates must be valid trading dates\n",
    "returns = utils.get_returns(start_date='2011-01-05', end_date='2016-01-05')\n",
    "\n",
    "# Display the first rows of the returns\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Data\n",
    "\n",
    "As we san see above, the `returns` dataframe, contains the stock returns for 490 assets. Eventhough we can't make 490-dimensional plots, we can plot the data for two assets at a time. This plot willl then show us visually how correlated the stock returns are for a pair of stocks.\n",
    "\n",
    "In the code below, we use the `.plot.scatter(x, y)` method to make a scatter plot of the returns of column `x` and column `y`. The `x` and `y` parameters are both integers and idicate the number of the columns we want to plot. For example, if we want to see how correlated the stock of `AAL` and `AAPL` are, we can choose `x=1` and `y=3`, since we can see from the dataframe above that stock `AAL` corresponds to column number `1`, and stock `AAPL` corresponds to column number `3`. You are encouraged to plot different pairs of stocks to see how correlated they are.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [10.0, 6.0]\n",
    "\n",
    "# Make scatter plot\n",
    "ax = returns.plot.scatter(x = 1, y = 3, grid = True, color = 'white', alpha = 0.5, linewidth = 0)\n",
    "ax.set_facecolor('lightslategray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation of Returns\n",
    "\n",
    "Apart from visualizing the correlation between stocks as we did above, we can also create a correlation dataframe that gives the correlation between every stock. In the code below, we can accomplish this using the `.corr()` method to calculate the correlation between all the paris of stocks in our `returns` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the correlation between all stock pairs in the returns dataframe\n",
    "returns.corr(method = 'pearson').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this is a better way to see how correlated the stock returns are than through visulaization. By looking at the table we can easily spot which pairs of stock have the highest correlation. \n",
    "\n",
    "# TODO:\n",
    "\n",
    "In the code below, make a scatter of equity `A` and equity `XOM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [10.0, 6.0]\n",
    "\n",
    "# Make scatter plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "In the code below, write a function `get_num_components(df, var_ret)` that takes a dataframe, `df`, and a value for the desired amount of variance you want to retain from the `df` dataframe,`var_ret`. In this case, the parameter `df` should be the `returns` dataframe obtained above. The parameter  `var_ret` must be anumber between 0 and 1. The function should return the number of principal components you need to retain that amount of variance. To do this, use Scikit-Learn's PCA() class and its `.explained_variance_ratio_`. The function should also print the total amount of variance retained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import resources\n",
    "\n",
    "\n",
    "\n",
    "def get_num_components(df, var_ret):\n",
    "    \n",
    "    # Implement Function\n",
    "    return needed_components\n",
    "        \n",
    "            \n",
    "num_components = get_num_components(returns, 0.9)\n",
    "\n",
    "print('\\nNumber of Principal Components Needed: ', num_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "In the previous section you calculated the number of principal compenents needed to retain a given amount of variance. As you might notice you can greatly reduce the dimensions of the data even if you retain a high level of variance (`var_ret` > 0.9). In the code below, use the number of components needed calculated in the last section, `num_components` to calculate by the percentage of dimensionality reduction. For example, if the original data was 100-dimensional, and the amount of components needed to retian a certain amount of variance is 70, then we are able to reduce the data by 30%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of dimensionality reduction\n",
    "\n",
    "print('We were able to reduce the dimenionality of the data by:', red_per, 'percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "[Solution notebook](pca_basics_solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar chvfz notebook.tar.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UdacityAI",
   "language": "python",
   "name": "udacityai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
